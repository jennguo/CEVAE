{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "from parse_data_uriver import Twins\n",
    "import numpy as np\n",
    "from numpy import shape, mean, sum, min, max\n",
    "from evaluation import EvaluatorTwins\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.stats import sem\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset = Twins(treatment='random',noise_bin=0.5)\n",
    "\n",
    "#RCT equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = Twins(treatment='conf_gest_3',noise_bin=0.333)\n",
    "\n",
    "#Used in main Figure of CEVAE paper, 3 noisy copies of binary GEST10 indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11984, 75)\n"
     ]
    }
   ],
   "source": [
    "X, T, yf, y_cf, xtype, rids = dataset.get_data()\n",
    "print shape(X)\n",
    "#len(xtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eclamp',\n",
       " 'gestatcat1',\n",
       " 'gestatcat2',\n",
       " 'gestatcat3',\n",
       " 'gestatcat4',\n",
       " 'gestatcat5',\n",
       " 'gestatcat6',\n",
       " 'gestatcat7',\n",
       " 'gestatcat8',\n",
       " 'gestatcat9',\n",
       " 'gestatcat10',\n",
       " 'gestatcat1',\n",
       " 'gestatcat2',\n",
       " 'gestatcat3',\n",
       " 'bord',\n",
       " 'gestatcat4',\n",
       " 'gestatcat6',\n",
       " 'gestatcat7',\n",
       " 'gestatcat8',\n",
       " 'gestatcat9',\n",
       " 'gestatcat10',\n",
       " 'gestatcat1',\n",
       " 'gestatcat2',\n",
       " 'gestatcat3',\n",
       " 'gestatcat4',\n",
       " 'gestatcat5',\n",
       " 'gestatcat6',\n",
       " 'gestatcat7',\n",
       " 'gestatcat8',\n",
       " 'gestatcat5',\n",
       " 'gestatcat9',\n",
       " 'gestatcat10',\n",
       " 'othermr',\n",
       " 'dmar',\n",
       " 'csex',\n",
       " 'cardiac',\n",
       " 'uterine',\n",
       " 'lung',\n",
       " 'diabetes',\n",
       " 'herpes',\n",
       " 'anemia',\n",
       " 'hydra',\n",
       " 'chyper',\n",
       " 'phyper',\n",
       " 'incervix',\n",
       " 'pre4000',\n",
       " 'preterm',\n",
       " 'renal',\n",
       " 'rh',\n",
       " 'hemo',\n",
       " 'tobacco',\n",
       " 'alcohol',\n",
       " 'orfath',\n",
       " 'adequacy',\n",
       " 'drink5',\n",
       " 'mpre5',\n",
       " 'meduc6',\n",
       " 'mrace',\n",
       " 'ormoth',\n",
       " 'frace',\n",
       " 'birattnd',\n",
       " 'stoccfipb_reg',\n",
       " 'mplbir_reg',\n",
       " 'cigar6',\n",
       " 'mager8',\n",
       " 'pldel',\n",
       " 'brstate_reg',\n",
       " 'feduc6',\n",
       " 'dfageq',\n",
       " 'nprevistq',\n",
       " 'data_year',\n",
       " 'crace',\n",
       " 'birmon',\n",
       " 'dtotord_min',\n",
       " 'dlivord_min']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y0 = yf*(1-T) + y_cf*T\n",
    "y1 = yf*T + y_cf*(1-T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0252002670227\n",
      "0.0869277967589\n"
     ]
    }
   ],
   "source": [
    "print mean(y1-y0)\n",
    "print abs(mean(yf[T==1])- mean(yf[T==0]) - mean(y1 - y0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication 1/5\n",
      "Replication 2/5\n",
      "Replication 3/5\n",
      "Replication 4/5\n",
      "Replication 5/5\n",
      "\n",
      "mean LR1 train_auc_fact: 0.778+-0.001, test_auc_fact: 0.770+-0.005\n",
      "mean LR2 train_auc_fact: 0.785+-0.001, test_auc_fact: 0.767+-0.006\n",
      "\n",
      "mean LR1 train_auc: 0.737+-0.001, test_auc: 0.734+-0.006\n",
      "mean LR2 train_auc: 0.712+-0.002, test_auc: 0.717+-0.005\n",
      "\n",
      "mean LR1 train_dir: 0.626+-0.003, test_dir: 0.610+-0.013\n",
      "mean LR2 train_dir: 0.619+-0.005, test_dir: 0.594+-0.012\n"
     ]
    }
   ],
   "source": [
    "lr1auc = list()\n",
    "lr1auc_te = list()\n",
    "lr2auc = list()\n",
    "lr2auc_te = list()\n",
    "\n",
    "lr1auc_fact = list()\n",
    "lr1auc_te_fact = list()\n",
    "lr2auc_fact = list()\n",
    "lr2auc_te_fact = list()\n",
    "\n",
    "lr1dir = list()\n",
    "lr1dir_te = list()\n",
    "lr2dir = list()\n",
    "lr2dir_te = list()\n",
    "\n",
    "\n",
    "\n",
    "for replic, ((Xtr, Ttr, Ytr, YCFtr), (Xte, Tte, Yte, YCFte)) in enumerate(dataset.get_train_test(n_splits=5)):        \n",
    "    \n",
    "    evaluator_tr = EvaluatorTwins(Ytr, Ttr, YCFtr)\n",
    "    evaluator_te = EvaluatorTwins(Yte, Tte, YCFte)\n",
    "    \n",
    "    \n",
    "    lr2_1 = LogisticRegression().fit(Xtr[Ttr.ravel() == 1], Ytr[Ttr.ravel() == 1].ravel())\n",
    "    lr2_0 = LogisticRegression().fit(Xtr[Ttr.ravel() == 0], Ytr[Ttr.ravel() == 0].ravel())\n",
    "    lr2y0, lr2y1 = lr2_0.predict_proba(Xtr)[:, 1][:, np.newaxis], lr2_1.predict_proba(Xtr)[:, 1][:, np.newaxis]\n",
    "    lr2y0t, lr2y1t = lr2_0.predict_proba(Xte)[:, 1][:, np.newaxis], lr2_1.predict_proba(Xte)[:, 1][:, np.newaxis]\n",
    "    \n",
    "    lr2auc.append(evaluator_tr.calc_stats(lr2y1, lr2y0)[0])\n",
    "    lr2auc_te.append(evaluator_te.calc_stats(lr2y1t, lr2y0t)[0])\n",
    "    \n",
    "    lr2auc_fact.append(evaluator_tr.calc_stats(lr2y1, lr2y0)[1])\n",
    "    lr2auc_te_fact.append(evaluator_te.calc_stats(lr2y1t, lr2y0t)[1])\n",
    "    \n",
    "    lr2dir.append(evaluator_tr.calc_dir_error(lr2y1, lr2y0))\n",
    "    lr2dir_te.append(evaluator_te.calc_dir_error(lr2y1t, lr2y0t))\n",
    "    \n",
    "   \n",
    "    lr1 = LogisticRegression().fit(np.concatenate([Xtr, Ttr], axis=1), Ytr.ravel())\n",
    "    lr1y0 = lr1.predict_proba(np.concatenate([Xtr, np.zeros_like(Ttr)], axis=1))[:, 1][:, np.newaxis]\n",
    "    lr1y1 = lr1.predict_proba(np.concatenate([Xtr, np.ones_like(Ttr)], axis=1))[:, 1][:, np.newaxis]\n",
    "    lr1y0t = lr1.predict_proba(np.concatenate([Xte, np.zeros_like(Tte)], axis=1))[:, 1][:, np.newaxis]\n",
    "    lr1y1t = lr1.predict_proba(np.concatenate([Xte, np.ones_like(Tte)], axis=1))[:, 1][:, np.newaxis]\n",
    "    \n",
    "    lr1auc.append(evaluator_tr.calc_stats(lr1y1, lr1y0)[0])\n",
    "    lr1auc_te.append(evaluator_te.calc_stats(lr1y1t, lr1y0t)[0])\n",
    "    \n",
    "    lr1auc_fact.append(evaluator_tr.calc_stats(lr1y1, lr1y0)[1])\n",
    "    lr1auc_te_fact.append(evaluator_te.calc_stats(lr1y1t, lr1y0t)[1])\n",
    "    \n",
    "    lr1dir.append(evaluator_tr.calc_dir_error(lr1y1, lr1y0))\n",
    "    lr1dir_te.append(evaluator_te.calc_dir_error(lr1y1t, lr1y0t))\n",
    "    \n",
    "                                                  \n",
    "    print 'Replication {}/{}'.format(replic + 1, 5)\n",
    "    #print 'LR1 train_auc_fact: {:0.3f}, test_auc_fact: {:0.3f}'.format(lr1auc_fact[-1], lr1auc_te_fact[-1])\n",
    "    #print 'LR2 train_auc_fact: {:0.3f}, test_auc_fact: {:0.3f}'.format(lr2auc_fact[-1], lr2auc_te_fact[-1])\n",
    "    #print 'LR1 train_auc: {:0.3f}, test_auc: {:0.3f}'.format(lr1auc[-1], lr1auc_te[-1])\n",
    "    #print 'LR2 train_auc: {:0.3f}, test_auc: {:0.3f}'.format(lr2auc[-1], lr2auc_te[-1])\n",
    "    \n",
    "    #print 'LR1 train_dir: {:0.3f}, test_dir: {:0.3f}'.format(lr1dir[-1], lr1dir_te[-1])\n",
    "    #print 'LR2 train_dir: {:0.3f}, test_dir: {:0.3f}'.format(lr2dir[-1], lr2dir_te[-1])\n",
    "\n",
    "print ''    \n",
    "print 'mean LR1 train_auc_fact: {:0.3f}+-{:0.3f}, test_auc_fact: {:0.3f}+-{:0.3f}'.format(mean(lr1auc_fact),sem(lr1auc_fact),mean(lr1auc_te_fact),sem(lr1auc_te_fact))\n",
    "print 'mean LR2 train_auc_fact: {:0.3f}+-{:0.3f}, test_auc_fact: {:0.3f}+-{:0.3f}'.format(mean(lr2auc_fact),sem(lr2auc_fact),mean(lr2auc_te_fact),sem(lr2auc_te_fact))\n",
    "print ''\n",
    "print 'mean LR1 train_auc: {:0.3f}+-{:0.3f}, test_auc: {:0.3f}+-{:0.3f}'.format(mean(lr1auc),sem(lr1auc),mean(lr1auc_te),sem(lr1auc_te))\n",
    "print 'mean LR2 train_auc: {:0.3f}+-{:0.3f}, test_auc: {:0.3f}+-{:0.3f}'.format(mean(lr2auc),sem(lr2auc),mean(lr2auc_te),sem(lr2auc_te))\n",
    "print ''\n",
    "print 'mean LR1 train_dir: {:0.3f}+-{:0.3f}, test_dir: {:0.3f}+-{:0.3f}'.format(mean(lr1dir),sem(lr1dir),mean(lr1dir_te),sem(lr1dir_te))\n",
    "print 'mean LR2 train_dir: {:0.3f}+-{:0.3f}, test_dir: {:0.3f}+-{:0.3f}'.format(mean(lr2dir),sem(lr2dir),mean(lr2dir_te),sem(lr2dir_te))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
